{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSC = pd.read_csv('./original_data/Base_station_basic_info.csv')\n",
    "CLD = pd.read_csv('./original_data/Cell-level_data.csv')\n",
    "ECD = pd.read_csv('./original_data/Energy_consumption_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = CLD.merge(BSC, on=['BS', 'CellName'], how='inner')\n",
    "fullmerged_df = merged_df.merge(ECD, on=['BS', 'Time'], how='left') # merge + wyjscie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cells_per_base = fullmerged_df.groupby('BS')['CellName'].nunique()\n",
    "one_cell_bases = unique_cells_per_base[unique_cells_per_base == 1].index\n",
    "two_cell_bases = unique_cells_per_base[unique_cells_per_base == 2].index\n",
    "four_cell_bases = unique_cells_per_base[unique_cells_per_base == 4].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullmerged_df_1 = fullmerged_df[fullmerged_df['BS'].isin(one_cell_bases)]\n",
    "fullmerged_df_2 = fullmerged_df[fullmerged_df['BS'].isin(two_cell_bases)]\n",
    "fullmerged_df_4 = fullmerged_df[fullmerged_df['BS'].isin(four_cell_bases)]\n",
    "\n",
    "fullmerged_df_24 = fullmerged_df[fullmerged_df['BS'].isin(four_cell_bases) | fullmerged_df['BS'].isin(two_cell_bases)]\n",
    "\n",
    "# print(len(fullmerged_df_2), len(fullmerged_df_24), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (fullmerged_df_24['CellName'] != 'Cell2') & (fullmerged_df_24['CellName'] != 'Cell3')\n",
    "fullmerged_df_24 = fullmerged_df_24[condition]\n",
    "fullmerged_df_2 = fullmerged_df_24\n",
    "\n",
    "joined_df_2 = fullmerged_df_2.pivot_table(index=['Time', 'BS'], columns='CellName', values=['load', 'ESMode1', 'ESMode2', 'ESMode3',\n",
    "       'ESMode4', 'ESMode5', 'ESMode6', 'Frequency', 'Bandwidth', 'TXpower'], aggfunc='sum', fill_value=999)\n",
    "\n",
    "# dokleic energy i antennas\n",
    "joined_df_2.columns = ['{}_{}'.format(col[1], col[0]) for col in joined_df_2.columns]\n",
    "joined_df_2 = joined_df_2.sort_index(axis=1)\n",
    "joined_df_2 = joined_df_2.reset_index()\n",
    "joined_df_2 = joined_df_2.merge(fullmerged_df_2[['Time', 'BS', 'RUType', 'Mode', 'Antennas', 'Energy']], on=['Time', 'BS'], how='left')\n",
    "joined_df_2 = joined_df_2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df_2['Time'] = pd.to_datetime(joined_df_2['Time'], format='%m/%d/%Y %H:%M')\n",
    "\n",
    "joined_df_2['Year'] = joined_df_2['Time'].dt.year\n",
    "joined_df_2['Day'] = joined_df_2['Time'].dt.day\n",
    "joined_df_2['Hour'] = joined_df_2['Time'].dt.hour\n",
    "joined_df_2['Month'] = joined_df_2['Time'].dt.month\n",
    "\n",
    "joined_df_2 = joined_df_2.sort_values(by=['BS','Time'])\n",
    "joined_df_2 = joined_df_2.reset_index()\n",
    "# joined_df_2.to_csv('./joined_df_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ewentualne wypelnienie dziur predykcjami i oczywistymi strzalami\n",
    "with open('./pickle/all_preds_loss_1_64.pkl', 'rb') as file:\n",
    "    all_preds_dict = pickle.load(file)\n",
    "\n",
    "joined_df_2.reset_index(inplace=True, drop=True)\n",
    "\n",
    "for index, row in joined_df_2.iterrows():\n",
    "    energy = row.Energy\n",
    "    \n",
    "    if np.isnan(energy):\n",
    "        try:\n",
    "            energy_pred = float(all_preds_dict[(row.BS, str(row.Time))])\n",
    "            joined_df_2.loc[index, 'Energy'] = energy_pred\n",
    "        except:\n",
    "            print(\"gowno\",row.BS, row.Time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df_2['Energy_1'] = joined_df_2['Energy'].shift(1, fill_value=0)\n",
    "bs = None\n",
    "past_energy_cell2_dict = {}\n",
    "for index, row in joined_df_2.iterrows():\n",
    "    time = row.Time\n",
    "    if bs != row.BS:\n",
    "        bs = row.BS\n",
    "        joined_df_2.at[index, 'Energy_1'] = 0.0\n",
    "    elif np.isnan(row.Energy_1):\n",
    "        try:\n",
    "            joined_df_2.at[index, 'Energy_1'] = joined_df_2.at[index-1, 'Energy_1']\n",
    "        except:\n",
    "            print('Mamy problem')\n",
    "    past_energy_cell2_dict[(bs, time)] = [joined_df_2.at[index, 'Energy_1']]\n",
    "    \n",
    "# with open('./pickle/past_energy_cell2_dict.pkl', 'wb') as file:\n",
    "#     pickle.dump(past_energy_cell2_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dict = {}\n",
    "for row in joined_df_2.itertuples(index=False):\n",
    "    bs = row.BS\n",
    "    bw = row.Cell1_Bandwidth\n",
    "    es_mode1 = row.Cell1_ESMode1\n",
    "    es_mode2 = row.Cell1_ESMode2\n",
    "    es_mode3 = row.Cell1_ESMode3\n",
    "    es_mode4 = row.Cell1_ESMode4\n",
    "    es_mode5 = row.Cell1_ESMode5\n",
    "    es_mode6 = row.Cell1_ESMode6\n",
    "    fr = row.Cell1_Frequency\n",
    "    txp = row.Cell1_TXpower\n",
    "    load = row.Cell1_load\n",
    "    hour = row.Hour\n",
    "    if bw != 999:\n",
    "        big_dict[(bs, hour)] = [bw, es_mode1, es_mode2, es_mode3, es_mode4, es_mode5, es_mode6, fr, txp, load]\n",
    "\n",
    "with open('./pickle/big_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(big_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_df_2[\"Info\"] = 0\n",
    "joined_df_2.to_csv('./joined_df_2.csv', index=False)\n",
    "for index, row in joined_df_2.iterrows():\n",
    "    if row.Cell1_Bandwidth == 999:\n",
    "        tmp_list = big_dict[(row.BS, row.Hour)]\n",
    "        joined_df_2.at[index, 'Cell1_Bandwidth'] = tmp_list[0]\n",
    "        joined_df_2.at[index, 'Cell1_ESMode1'] = tmp_list[1]\n",
    "        joined_df_2.at[index, 'Cell1_ESMode2'] = tmp_list[2]\n",
    "        joined_df_2.at[index, 'Cell1_ESMode3'] = tmp_list[3]\n",
    "        joined_df_2.at[index, 'Cell1_ESMode4'] = tmp_list[4]\n",
    "        joined_df_2.at[index, 'Cell1_ESMode5'] = tmp_list[5]\n",
    "        joined_df_2.at[index, 'Cell1_ESMode6'] = tmp_list[6]\n",
    "        joined_df_2.at[index, 'Cell1_Frequency'] = tmp_list[7]\n",
    "        joined_df_2.at[index, 'Cell1_TXpower'] = tmp_list[8]\n",
    "        joined_df_2.at[index, 'Cell1_load'] = tmp_list[9]\n",
    "        # joined_df_2.at[index, 'Info'] = 1\n",
    "# print(joined_df_2[\"Info\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RUType\n",
       "0    25090\n",
       "3     1259\n",
       "2      139\n",
       "4      139\n",
       "1       48\n",
       "5       24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zmiana stringa np. RUType na liczby\n",
    "label_encoders = {}\n",
    "object_cols = ['RUType', 'Mode'] \n",
    "\n",
    "for col in object_cols:\n",
    "    le = LabelEncoder()\n",
    "    joined_df_2[col] = le.fit_transform(joined_df_2[col])\n",
    "    label_encoders[col] = le\n",
    "joined_df_2['RUType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RUType0  RUType1  RUType2  RUType3  RUType4  RUType5\n",
       "1        0        0        0        0        0          25090\n",
       "0        0        0        1        0        0           1259\n",
       "                           0        1        0            139\n",
       "                  1        0        0        0            139\n",
       "         1        0        0        0        0             48\n",
       "         0        0        0        0        1             24\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joined_df_2.to_csv('./joined_df_2.csv', index=False)\n",
    "Encoded_rutype = torch.nn.functional.one_hot(torch.tensor(joined_df_2['RUType'].values).long(), len(joined_df_2['RUType'].value_counts()))\n",
    "Encoded_rutype = pd.DataFrame(Encoded_rutype, columns=[f\"RUType{i}\" for i in range(len(joined_df_2['RUType'].value_counts()))])\n",
    "Encoded_rutype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df_2_numpy = joined_df_2.to_numpy()\n",
    "Encoded_rutype_numpy = Encoded_rutype.to_numpy()\n",
    "chuj = joined_df_2.columns\n",
    "joined_df_2 = np.concatenate((joined_df_2_numpy,Encoded_rutype_numpy), axis=1)\n",
    "joined_df_2 = pd.DataFrame(joined_df_2, columns = chuj.append(Encoded_rutype.columns))\n",
    "\n",
    "# joined_df_2 = joined_df_2.drop([\"BS\", \"Year\", \"Month\", \"RUType\", \"Time\", \"index\"], axis=1)\n",
    "joined_df_2 = joined_df_2.drop([\"Year\", \"Month\", \"RUType\", \"index\"], axis=1)\n",
    "# joined_df_2 = joined_df_2.drop([\"BS\", \"Time\"], axis=1)\n",
    "# joined_df_2 = joined_df_2.dropna(subset=['Energy'])\n",
    "cols = [col for col in joined_df_2 if col != 'Energy'] + ['Energy']\n",
    "joined_df_2 = joined_df_2[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Time', 'BS', 'Cell0_Bandwidth', 'Cell0_ESMode1', 'Cell0_ESMode2',\n",
      "       'Cell0_ESMode3', 'Cell0_ESMode4', 'Cell0_ESMode5', 'Cell0_ESMode6',\n",
      "       'Cell0_Frequency', 'Cell0_TXpower', 'Cell0_load', 'Cell1_Bandwidth',\n",
      "       'Cell1_ESMode1', 'Cell1_ESMode2', 'Cell1_ESMode3', 'Cell1_ESMode4',\n",
      "       'Cell1_ESMode5', 'Cell1_ESMode6', 'Cell1_Frequency', 'Cell1_TXpower',\n",
      "       'Cell1_load', 'Mode', 'Antennas', 'Day', 'Hour', 'Energy_1', 'RUType0',\n",
      "       'RUType1', 'RUType2', 'RUType3', 'RUType4', 'RUType5', 'Energy'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "joined_df_2.to_csv('./prepared_data/TwoOrFour_Cell_merged_with_preds.csv', index=False)\n",
    "print(joined_df_2.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
